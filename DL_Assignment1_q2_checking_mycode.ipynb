{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-dTvS-193wn",
        "outputId": "26ef8528-0c14-4216-fdf3-491e6e9f77d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "<class 'list'>\n",
            "Preactivation values:\n",
            "Layer 1: [[ 14.7046515    9.99437054 -15.31676186 ...  -9.54617159   0.821204\n",
            "    6.60202476]\n",
            " [ 13.62458505   9.66756693 -22.12166808 ...   4.60885828  -1.26652693\n",
            "    5.02582313]\n",
            " [  3.79606678  -0.6080465  -12.95419227 ...   5.23325718   2.28345347\n",
            "    1.29106854]\n",
            " ...\n",
            " [ 23.43667169  11.93479512 -26.79796153 ...  -1.11690125  -0.17654677\n",
            "  -10.28691348]\n",
            " [  4.47031502   2.06339547  -2.89695654 ...   4.12249782  -0.23639941\n",
            "    1.78665773]\n",
            " [  6.6943501    1.96986902  -6.08049058 ...  -4.60336109   0.31527671\n",
            "   -1.67274659]]\n",
            "Layer 2: [[ 8.66407339e-01 -5.29967540e+00  4.34278295e-01  6.97920620e+00\n",
            "   1.84877390e+00 -4.13447409e-01 -2.48190373e-01  1.20114213e+00\n",
            "  -1.66215995e+01 -2.20695728e+00]\n",
            " [-6.77901427e+00 -8.34770604e+00  5.24986644e+00  4.72608851e+00\n",
            "  -5.19018179e+00  4.08574700e+00 -2.15147937e+00 -9.08703945e-01\n",
            "  -8.80730594e+00  9.62265163e-02]\n",
            " [-1.72424409e+00  4.13978384e-03  1.90238378e+00 -7.37413012e-01\n",
            "  -1.63459242e-01  1.02534216e+00  2.84041018e+00 -1.33604341e+00\n",
            "  -1.15396649e+01  2.24615384e+00]\n",
            " [ 2.65567878e-01 -3.60840426e+00  2.98968448e+00  5.42286283e+00\n",
            "  -1.74016790e+00  2.06585308e+00  3.11253759e+00  2.11949413e-01\n",
            "  -1.29841313e+01 -3.30122499e-01]\n",
            " [-2.32114541e+00  8.83981174e-01  4.70223890e+00  4.15073749e+00\n",
            "  -2.42138975e+00  4.36404908e+00 -2.25120933e+00  2.93579323e+00\n",
            "  -8.97576119e+00  4.71276202e-01]\n",
            " [-2.45693658e+00  5.14095048e-01  5.00143524e+00  7.27328562e+00\n",
            "  -6.48960873e+00  4.42615794e+00 -1.79951721e+00 -2.27770413e+00\n",
            "  -1.06598595e+01  2.50639310e+00]\n",
            " [-5.88916470e+00 -1.02134540e+00  3.66357466e+00 -8.31478526e-01\n",
            "   5.20962305e+00  2.65252849e+00 -3.06400697e+00 -1.21759177e+00\n",
            "  -1.26482020e+01 -1.26434415e+00]\n",
            " [-4.47594647e+00 -2.60037497e+00  9.05535239e-01  8.46411310e+00\n",
            "  -1.13434790e+01  5.51059447e+00 -3.57396907e+00 -2.94721591e+00\n",
            "  -1.01887564e+01  9.88734429e-01]\n",
            " [-2.21786874e+00 -1.10365451e+01 -1.48142602e-01  2.98003534e+00\n",
            "   2.62675985e+00  5.46326175e-01  6.54128787e-01 -1.20162376e-01\n",
            "  -1.09894229e+01 -9.16095076e-01]\n",
            " [-2.72864417e+00 -1.70028594e+00 -3.49306648e+00  4.45227778e+00\n",
            "  -1.61549435e+00  3.76615530e-01  8.14336059e-01 -1.77757195e+00\n",
            "  -1.41607984e+01 -4.21818369e+00]]\n",
            "\n",
            "Activation values:\n",
            "Layer 1: [[9.99999589e-01 9.99954346e-01 2.22851081e-07 ... 7.14692651e-05\n",
            "  6.94491856e-01 9.98644224e-01]\n",
            " [9.99998790e-01 9.99936700e-01 2.46991280e-10 ... 9.90135099e-01\n",
            "  2.19852364e-01 9.93476654e-01]\n",
            " [9.78034390e-01 3.52504947e-01 2.36627247e-06 ... 9.94692207e-01\n",
            "  9.07497360e-01 7.84327995e-01]\n",
            " ...\n",
            " [1.00000000e+00 9.99993442e-01 2.30034609e-12 ... 2.46586521e-01\n",
            "  4.55977591e-01 3.40749666e-05]\n",
            " [9.88685766e-01 8.87294175e-01 5.23042172e-02 ... 9.84054393e-01\n",
            "  4.41173850e-01 8.56517016e-01]\n",
            " [9.98763644e-01 8.77597044e-01 2.28183571e-03 ... 9.91874028e-03\n",
            "  5.78172721e-01 1.58058330e-01]]\n",
            "Layer 2: [[2.18353546e-03 4.58421041e-06 1.41738878e-03 9.86086612e-01\n",
            "  5.83171950e-03 6.07192494e-04 7.16302742e-04 3.05164297e-03\n",
            "  5.54900819e-11 1.01021765e-04]\n",
            " [3.12035891e-06 6.50025468e-07 5.22734385e-01 3.09604455e-01\n",
            "  1.52836024e-05 1.63196342e-01 3.19093109e-04 1.10572705e-03\n",
            "  4.10514661e-07 3.02053371e-03]\n",
            " [4.59119477e-03 2.58555211e-02 1.72563995e-01 1.23168884e-02\n",
            "  2.18658298e-02 7.17886608e-02 4.40889621e-01 6.76891604e-03\n",
            "  2.50693243e-07 2.43359122e-01]\n",
            " [4.65380197e-03 9.66859067e-05 7.09376356e-02 8.08337336e-01\n",
            "  6.26221418e-04 2.81618919e-02 8.02104835e-02 4.41084397e-03\n",
            "  8.19476788e-09 2.56509146e-03]\n",
            " [3.56430437e-04 8.78908311e-03 4.00121447e-01 2.30503654e-01\n",
            "  3.22432803e-04 2.85310568e-01 3.82250124e-04 6.83965546e-02\n",
            "  4.59104836e-07 5.81712075e-03]\n",
            " [5.07743667e-05 9.90711396e-04 8.80591001e-02 8.53937972e-01\n",
            "  9.00072002e-07 4.95375454e-02 9.79846671e-05 6.07413138e-05\n",
            "  1.39046591e-08 7.26425715e-03]\n",
            " [1.16533539e-05 1.51536761e-03 1.64116757e-01 1.83221373e-03\n",
            "  7.70181736e-01 5.97119363e-02 1.96517554e-04 1.24534386e-03\n",
            "  1.35219197e-08 1.18846114e-03]\n",
            " [2.27855722e-06 1.48665533e-05 4.95230918e-04 9.49415696e-01\n",
            "  2.37207525e-09 4.95175973e-02 5.61543945e-06 1.05094306e-05\n",
            "  7.52693377e-09 5.38196290e-04]\n",
            " [2.76064976e-03 4.08421726e-07 2.18716703e-02 4.99381411e-01\n",
            "  3.50757345e-01 4.38011899e-02 4.87869859e-02 2.24922866e-02\n",
            "  4.28128112e-07 1.01476255e-02]\n",
            " [7.24047935e-04 2.02477897e-03 3.37118767e-04 9.51485327e-01\n",
            "  2.20395205e-03 1.61571394e-02 2.50301863e-02 1.87418619e-03\n",
            "  7.84956924e-09 1.63255764e-04]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Reshape the data to flatten the images\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
        "\n",
        "class neuralNetwork:\n",
        "    def __init__(self, size):\n",
        "        self.W = []\n",
        "        self.B = []\n",
        "        self.preactivation = []\n",
        "        self.activation = []\n",
        "        for i in range(1, len(size)):\n",
        "            w = np.random.uniform(low=-1, high=1, size=(size[i], size[i-1]))\n",
        "            b = np.random.uniform(low=-1, high=1, size=(size[i],))\n",
        "            self.W.append(w)\n",
        "            self.B.append(b)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, input, size, activation_function=\"sigmoid\"):\n",
        "        for i in range(len(size)-2):\n",
        "            Y = np.dot(input, self.W[i].T) + self.B[i]\n",
        "            if i < len(self.preactivation):\n",
        "                self.preactivation[i] = Y\n",
        "            else:\n",
        "                self.preactivation.append(Y)\n",
        "            if activation_function.lower() == \"sigmoid\":\n",
        "                Z = self.sigmoid(Y)\n",
        "            else:\n",
        "                print(\"NO Activation Function\")\n",
        "            if i < len(self.activation):\n",
        "                self.activation[i] = Z\n",
        "            else:\n",
        "                self.activation.append(Z)\n",
        "            input = Z\n",
        "        i = len(size) - 2\n",
        "        Y = np.dot(input, self.W[i].T) + self.B[i]\n",
        "\n",
        "        if i < len(self.preactivation):\n",
        "            self.preactivation[i] = Y\n",
        "        else:\n",
        "            self.preactivation.append(Y)\n",
        "        Z = self.softmax(Y)\n",
        "        if i < len(self.activation):\n",
        "            self.activation[i] = Z\n",
        "        else:\n",
        "            self.activation.append(Z)\n",
        "        return self.preactivation, self.activation\n",
        "\n",
        "# Define the neural network architecture\n",
        "size = [784, 256, 10]\n",
        "print(type(size))\n",
        "\n",
        "# Create an instance of the neural network\n",
        "net = neuralNetwork(size)\n",
        "\n",
        "# Forward pass through the neural network (for testing purposes)\n",
        "preactivation, activation = net.forward(x_train[:10], size)\n",
        "\n",
        "# Print the preactivation and activation values\n",
        "print(\"Preactivation values:\")\n",
        "for layer, values in enumerate(preactivation):\n",
        "    print(f\"Layer {layer + 1}: {values}\")\n",
        "\n",
        "print(\"\\nActivation values:\")\n",
        "for layer, values in enumerate(activation):\n",
        "    print(f\"Layer {layer + 1}: {values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qH7s0X7_-Aho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}